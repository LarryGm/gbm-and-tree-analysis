---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
tree.carseats# large file to open
set.seed(2)
train<-sample(1:nrow(Carseat2), 200)
Carseats.test<-Carseat2[-train,]
High.test<-High[-train]
tree.carseats<-tree(High~.-Sales,Carseat2,subset=train)
tree.pred<-predict(tree.carseats,Carseats.test,type="class")
cv.carseats<-cv.tree(tree.carseats,FUN=prune.misclass )
names(cv.carseats)
cv.carseats

par(mfrow=c(1,2))
plot(cv.carseats$size, cv.carseats$dev,type="b")
plot(cv.carseats$k, cv.carseats$dev,type="b")
prune.carseats<-prune.misclass(tree.carseats,best=9)
par(mfrow=c(1,1))
plot(prune.carseats)
text(prune.carseats ,pretty =0)
tree.pred<-predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)

#Fitting regression trees with Boston Housing data
train<-sample(1:nrow(Boston),nrow(Boston)/2)
tree.boston<-tree(medv~.,Boston, subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston, pretty=0)
cv.boston<-cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type='b')
prune.boston<-prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston, pretty=0)
#bagging and random forests
yhat.bag<-predict(bag.boston, newdata=Boston[-train ,])
abline(0,1)
boston.test<-Boston[-train ,"medv"]
set.seed(1)
rf.boston<-randomForest(medv~.,data=Boston, subset=train,
mtry=6, importance =TRUE)
yhat.rf<- predict(rf.boston ,newdata=Boston[-train ,])
importance(rf.boston)
par(mfrow=c(1,2))
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
boost.boston<-gbm::gbm(medv???.,data=Boston[train,], distribution="gaussian",n.trees=5000, interaction.depth = 4, shrinkage=0.01)
yhat.boost=predict (boost.boston ,newdata =Boston[-train ,],
n.trees=5000)
mean((yhat.boost - boston.test)^2)

library(e1071)
svmfit<-e10 (y~., data=dat , kernel ="linear", cost=0.1,
scale=FALSE)
svmfit$index
summary(svmfit)
svmfit<-e1071::svm(y~., data=dat , kernel ="linear", cost=0.1,scale=FALSE)
svmfit$index
tune.out<-tune(svm ,y~.,data=dat ,kernel ="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod=tune.out$best.model
summary(bestmod)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1),20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,] + 1
testdat<-data.frame(x=xtest,y=as.factor(ytest))
ypred<-predict(bestmod,testdat)
table(predict =ypred , truth=testdat$y )
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x,y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
svmfit<-svm(y???., data=dat , kernel ="linear", cost=1)
summary(svmfit)
plot(svmfit ,dat)
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y<-c(rep(1,150) ,rep(2,50))
dat<-data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train<-sample (200,100)
svmfit<-svm(y~.,data=dat[train,], kernel ="radial", gamma=1, cost=1)
plot(svmfit , dat[train ,])
svmfit<-svm(y~., data=dat[train,], kernel ="radial",gamma=1,cost=1e5)
plot(svmfit ,dat[train ,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel ="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary (tune.out)
table(true=dat[-train,"y"],pred=predict (tune.out$best.model,newx=dat[-train,]))
library(ROCR)
rocplot<-function(pred,truth,...){
+ svmfit.opt=svm(y???., data=dat[train ,], kernel ="radial",
gamma=2, cost=1, decision .values =T)
fitted =attributes (predict (svmfit.opt ,dat[train ,], decision .
values=TRUE))$decision .values
Now we can produce the ROC plot.
par(mfrow=c(1,2))
rocplot (fitted ,dat[train ,"y"], main="Training Data")
+ perf = performance (predob ,"tpr","fpr")
+ plot(perf,...)}
svmfit.opt<-svm(y~.,data=dat[train,],kernel ="radial",gamma=2, cost=1, decision.values=T)
fitted<-attributes(predict(svmfit.opt ,dat[train,], decision.values=TRUE))$decision.values
#Now we can produce the ROC plot.
par(mfrow=c(1,2))
rocplot(fitted ,dat[train,"y"],main="Training Data")
svmfit.opt<-svm(y~.,data=dat[train,],kernel ="radial",gamma=2, cost=1, decision.values =T)
fitted<-attributes(predict(svmfit.opt ,dat[train ,], decision.values=TRUE))$decision.values

rocplot(fitted,dat[train,"y"], main="Training Data")
svmfit.flex<-svm(y~.,data=dat[train,], kernel ="radial",gamma=50, cost=1, decision.values =T)
fitted<-attributes(predict(svmfit.flex ,dat[train,], decision.values=T))$decision.values
tune.out<-tune(svm,y~.,data=dat ,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100) ))
rocplot(fitted ,dat[train,"y"],add=T,col="red ")
svmfit<-svm(y~.,data=dat, kernel="linear", cost=1, scale=FALSE)
plot(svmfit , dat)
xtest<-matrix(rnorm (20*2) , ncol=2)
ytest<-sample (c(-1,1), 20, rep=TRUE)
xtest[ytest==1set.seed(1)
,]=xtest[ytest==1,] + 1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred=predict(bestmod,testdat)
table(predict =ypred , truth=testdat$y )
dat<-data.frame(x=x,y=as.factor(y))
svmfit<-svm(y~.,data=dat, kernel ="linear", cost=1e5)
summary(svmfit)
set.seed(1)
x<-matrix(rnorm (20*2), ncol=2)
y<-c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
plot(x, col=(3-y))
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~.,data=dat, kernel ="linear", cost=10,scale=FALSE)
plot(svmfit , dat)
svmfit$index
summary(svmfit)
svmfit<-svm(y~.,data=dat, kernel="linear",cost=0.1,scale=FALSE)
plot(svmfit , dat)
svmfit$index
set.seed(1)
tune.out<-tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100) ))
summary (tune.out)
bestmod<-tune.out$best.model
summary(bestmod)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1),20,rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,] + 1
testdat<-data.frame(x=xtest,y=as.factor(ytest))
ypred<-predict (bestmod ,testdat)
table(predict=ypred, truth=testdat$y)
svmfit<-svm(y~.,data=dat, kernel="linear", cost=.01,scale=FALSE)
ypred<-predict (svmfit ,testdat )
table(predict=ypred, truth=testdat$y )
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch =19)
dat<-data.frame(x=x,y=as.factor(y))
svmfit<-svm(y~.,data=dat, kernel="linear", cost=1e5)
summary(svmfit)
svmfit<-svm(y~., data=dat, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit ,dat)
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y<-c(rep(1,150) ,rep(2,50))
dat<-data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample (200,100)
svmfit<-svm(y~.,data=dat[train,],kernel="radial", gamma=1,cost=1)
plot(svmfit , dat[train ,])
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1e5)
plot(svmfit,dat[train ,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary (tune.out)
table(true=dat[-train,"y"], pred=predict (tune.out$best.model,newx=dat[-train,]))

rocplot<-function(pred,truth,...){
predob = prediction(pred,truth)
perf = performance (predob,"tpr","fpr")
plot(perf,...)}

svmfit.opt<-svm(y~.,data=dat[train,], kernel ="radial",gamma=2,cost=1, decision.values=T)
fitted<-attributes(predict(svmfit.opt,dat[train,], decision.values=TRUE))$decision.values

par(mfrow=c(1,2))
rocplot(fitted,dat[train ,"y"], main="Training Data")
svmfit.flex=svm(y~.,data=dat[train,], kernel ="radial",gamma=50, cost=1, decision.values =T)
fitted<-attributes(predict(svmfit.flex ,dat[train,], decision.values=T))$decision.values
rocplot(fitted,dat[train,"y"],add=T,col="red")
fitted<-attributes(predict(svmfit.opt ,dat[-train,],decision.values=T))$decision.values
rocplot(fitted,dat[-train ,"y"],main="Test Data")
fitted<-attributes(predict(svmfit.flex ,dat[- train,],decision.values=T))$decision.values
rocplot(fitted ,dat[-train ,"y"],add=T,col="red")

set.seed(1)
x<-rbind(x,matrix(rnorm(50*2), ncol=2))
y<-c(y,rep(0,50))
x[y==0,2]= x[y==0,2]+2
dat<-data.frame(x=x, y=as.factor(y))
par(mfrow=c(1,1))
plot(x,col=(y+1))
We now fit an SVM to the data:
svmfit=svm(y???., data=dat , kernel ="radial", cost=10, gamma =1)
plot(svmfit , dat)
flexmix::